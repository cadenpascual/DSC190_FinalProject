# E. Outline of Work for Completing the Project

The completion of this project will proceed through several interconnected phases, beginning with comprehensive data collection and preparation. The initial phase involves finalizing the data scraping process for both CAPES (Course And Professor Evaluation System) and SET (Student Evaluation of Teaching) datasets, ensuring that all DSC course evaluation data is collected and verified for completeness and quality. This will be followed by extensive data cleaning and integration work, where the existing CAPES dataset (683 rows) and SET dataset (149 rows) will be standardized, merged where applicable, and validated for accuracy. The data preparation phase will address missing values, handle inconsistencies, standardize course naming conventions, and verify that all required metrics—including enrollment numbers, grades, study hours, difficulty scores, and recommendation ratings—are present and correctly formatted.

Once the data foundation is established, the project will move into a comprehensive analysis phase that encompasses exploratory data analysis, comparative studies, and temporal trend examination. The exploratory analysis will generate statistical summaries of key metrics and identify patterns in course difficulty, study hours, grades, and recommendation ratings across different course levels. A comparative analysis will examine the differences between CAPES and SET evaluation systems, compare metrics across course levels (Lower, Lower-Mid, Upper, Upper-Mid, and Graduate), and analyze instructor-specific performance patterns. Additionally, temporal analysis will track changes in course difficulty and student satisfaction over the 16-year period from 2007 to 2025, identifying seasonal trends and long-term patterns that may inform departmental decision-making.

The visualization and reporting phase will build upon the five existing CAPES visualizations by refining them for publication quality and creating additional visualizations that compare CAPES and SET data, showcase instructor-specific performance dashboards, and present time-series analyses of key metrics. All visualizations will be accompanied by comprehensive documentation that explains data sources, collection methods, and interpretation guidelines. The project will then advance to statistical modeling and advanced analysis, where predictive models for course difficulty will be developed, factors influencing student satisfaction will be identified, and correlations between different evaluation metrics will be examined through hypothesis testing.

The final phase will focus on synthesizing all findings into actionable insights and recommendations for the DSC department, organizing all code into a clear and reproducible structure, and preparing a comprehensive project report that includes methodology, findings, conclusions, and limitations. The report will incorporate all visualizations with detailed interpretations and will be supplemented by presentation materials. Throughout the project, careful attention will be paid to code documentation, reproducibility, and data validation to ensure that the work can be easily understood, replicated, and extended in the future.

